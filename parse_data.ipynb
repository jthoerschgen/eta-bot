{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse GroupMe message jsons\n",
    "\n",
    "The purpose of this notebook is to extract data from data exported from GroupMe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import unicodedata\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_me_convo_path: Path = Path(\"Data/groupme_export\")\n",
    "training_data_path: Path = Path(f\"Data/training-data-{date.today()}/training_data.txt\")\n",
    "image_csv_path: Path = Path(\"/home/jimmy/GitHub/etaBot/images/images.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_convo(input_path: Path, output_path: Path, image_url_csv_path: Path | None = None) -> None:\n",
    "    \"\"\"Parse a GroupMe message.json file and write the text to a \n",
    "    given output folder\n",
    "\n",
    "    Args:\n",
    "        input_path (Path): Path for input data\n",
    "        output_path (Path): Path for where output file will go\n",
    "\n",
    "    Returns:\n",
    "        None: Returns None\n",
    "    \"\"\"\n",
    "    with open(input_path, \"r\", encoding=\"utf-8-sig\") as data_file:\n",
    "        data = data_file.read()\n",
    "    data_json = json.loads(data)\n",
    "\n",
    "    phone_number_re: re.Pattern[str] = re.compile(\n",
    "        r\"(\\+\\d{1,3}\\s?)?((\\(\\d{3}\\)\\s?)|(\\d{3})(\\s|-?))(\\d{3}(\\s|-?))(\\d{4})(\\s?(([E|e]xt[:|.|]?)|x|X)(\\s?\\d+))?\"\n",
    "    )  # Match phone numbers to remove them from output\n",
    "\n",
    "    url_re: re.Pattern[str] = re.compile(r\"http\\S+\")\n",
    "    # Match urls to remove them from output\n",
    "\n",
    "    with open(output_path, \"a\") as output_file:\n",
    "        for message in data_json:\n",
    "            msg_txt: str = message[\"text\"]\n",
    "            if not message[\"text\"]:\n",
    "                # skip empty messages\n",
    "                continue\n",
    "            if message[\"name\"] == \"GroupMe\" or message[\"sender_id\"] == \"system\":\n",
    "                # skip system messages\n",
    "                continue\n",
    "            if \"event\" in message.keys():\n",
    "                # skip events like polls, calandar events, etc.\n",
    "                continue\n",
    "            if image_url_csv_path and message[\"attachments\"]:\n",
    "                for attachment in message[\"attachments\"]:\n",
    "                    if attachment[\"type\"] == \"image\":\n",
    "                        with open(image_url_csv_path, \"a\") as csv_file:\n",
    "                            csv.writer(csv_file).writerow([attachment[\"url\"]])\n",
    "            if \"FRATGPT\" in msg_txt.upper():\n",
    "                # keep the bot ignorant of itself\n",
    "                continue\n",
    "\n",
    "            # replace unicode apostrophe with ascii apostrophe\n",
    "            msg_txt = msg_txt.replace(\"\\u2019\", \"'\")\n",
    "\n",
    "            # remove unicode characters\n",
    "            msg_txt = (\n",
    "                unicodedata.normalize(\"NFKD\", msg_txt).encode(\"ascii\", \"ignore\")\n",
    "            ).decode()\n",
    "\n",
    "            # remove urls and phone numbers\n",
    "            msg_txt = re.sub(url_re, \"\", msg_txt)\n",
    "            msg_txt = re.sub(phone_number_re, \"\", msg_txt)\n",
    "\n",
    "            # make double new line only one line\n",
    "            msg_txt = msg_txt.replace(\"\\n\\n\", \"\\n\")\n",
    "\n",
    "            # remove whitespace on edges\n",
    "            msg_txt = msg_txt.strip()\n",
    "\n",
    "            if len(msg_txt) == 0 or not msg_txt:\n",
    "                # if after cleaning, message is empty, skip it\n",
    "                continue\n",
    "\n",
    "            # write to output file\n",
    "            # output_file.write(json.dumps(message, indent=2))  # write raw msg\n",
    "            if msg_txt.endswith(\"\\n\"):\n",
    "                output_file.write(msg_txt)\n",
    "            else:\n",
    "                output_file.write(msg_txt + \"\\n\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_training_data(training_data_path: Path) -> None:\n",
    "    \"\"\"Shuffles training data\n",
    "\n",
    "    Args:\n",
    "        training_data_path (Path): Path of training data text file\n",
    "\n",
    "    Returns:\n",
    "        None: Returns None\n",
    "    \"\"\"\n",
    "    with open(training_data_path, \"r\") as training_data_file:\n",
    "        text_lines: list[str] = [(random.random(), line) for line in training_data_file]\n",
    "\n",
    "    text_lines.sort()\n",
    "\n",
    "    with open(training_data_path, \"w\") as training_data_file:\n",
    "        for _, line in text_lines:\n",
    "            training_data_file.write(line)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Folders if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "image_csv_path.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear Old Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(image_csv_path, \"w\") as json_file:\n",
    "    pass\n",
    "with open(training_data_path,'w') as file:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make list of file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths: list[Path] = [file for file in group_me_convo_path.iterdir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse GroupMe message json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in tqdm(file_paths, desc=\"Parsing Files\", disable=True):\n",
    "    parse_convo(\n",
    "        input_path=file_path/\"message.json\", \n",
    "        output_path=training_data_path,\n",
    "        image_url_csv_path=image_csv_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_training_data(training_data_path=training_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://i.groupme.com/1244x2208.jpeg.5d298696fd494d3998a8913821d955af\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "with open(image_csv_path, \"r\") as csv_file:\n",
    "    print(random.choice(list(csv.reader(csv_file))[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eta-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
